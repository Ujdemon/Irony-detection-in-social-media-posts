{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"election.csv\", encoding='utf-8')\n",
    "test_data = pd.read_csv(\"SemEval2018-T3-train-taskA.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = train_data[\"Tweets\"]\n",
    "test_tweets = test_data[\"Tweet text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_data['Task A']\n",
    "test_classes = test_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = train_tweets.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'url')\n",
    "processed_train = processed_train.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "processed_test = test_tweets.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'url')\n",
    "processed_test = processed_test.str.replace(r'\\d+(\\.\\d+)?', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = processed_train.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed_train = processed_train.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed_train = processed_train.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "processed_test = processed_test.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed_test = processed_test.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed_test = processed_test.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = processed_train.str.lower()\n",
    "processed_test = processed_test.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed_train = processed_train.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "\n",
    "processed_test = processed_test.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed_train = processed_train.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))\n",
    "\n",
    "processed_test = processed_test.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# create bag-of-words\n",
    "all_words_train = []\n",
    "all_words_test = []\n",
    "for message in processed_train:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words_train.append(w)\n",
    "        \n",
    "for message in processed_test:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words_test.append(w)\n",
    "        \n",
    "all_words_train = nltk.FreqDist(all_words_train)\n",
    "all_words_test = nltk.FreqDist(all_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features_train = list(all_words_train.keys())\n",
    "word_features_test = list(all_words_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features_train(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features_train:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "def find_features_test(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features_test:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do it for all the messages\n",
    "messages_train = list(zip(processed_train,train_classes))\n",
    "messages_test = list(zip(processed_test,test_classes))\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages_train)\n",
    "np.random.shuffle(messages_test)\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets_train = [(find_features_train(text), label) for (text, label) in messages_train]\n",
    "featuresets_test = [(find_features_test(text), label) for (text, label) in messages_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3817\n",
      "1081\n"
     ]
    }
   ],
   "source": [
    "print(len(featuresets_test))\n",
    "print(len(featuresets_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 50.19648938957296\n",
      "Decision Tree Accuracy: 49.4629290018339\n",
      "Random Forest Accuracy: 45.95231857479696\n",
      "Logistic Regression Accuracy: 48.72936861409484\n",
      "SGD Classifier Accuracy: 47.157453497511135\n",
      "Naive Bayes Accuracy: 47.55043227665706\n",
      "SVM Linear Accuracy: 47.786219544144615\n",
      "XGBoost Accuracy: 49.85590778097983\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(featuresets_train)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, featuresets_test)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 49.85590778097983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(featuresets_train)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, featuresets_test)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_features, labels = zip(*featuresets_test)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.27      0.34      1916\n",
      "           1       0.48      0.69      0.57      1901\n",
      "\n",
      "    accuracy                           0.48      3817\n",
      "   macro avg       0.48      0.48      0.46      3817\n",
      "weighted avg       0.48      0.48      0.46      3817\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not irony</th>\n",
       "      <th>irony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>not irony</th>\n",
       "      <td>517</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irony</th>\n",
       "      <td>587</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted      \n",
       "                 not irony irony\n",
       "actual not irony       517  1399\n",
       "       irony           587  1314"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['not irony', 'irony']],\n",
    "    columns = [['predicted', 'predicted'], ['not irony', 'irony']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet index  Label                                         Tweet text\n",
       "0            1      1  Sweet United Nations video. Just in time for C...\n",
       "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
       "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3            4      0                3 episodes left I'm dying over here\n",
       "4            5      1  I can't breathe! was chosen as the most notabl..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"SemEval2018-T3-train-taskA.txt\", sep='\\t')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet index</th>\n",
       "      <th>tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@Callisto1947 Can U Help?||More conservatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>GONNA WIN http://t.co/Mc9ebqjAqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>@mickymantell He is exactly that sort of perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>So much at work mate 10/10 #boring 100% #dead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet index                                         tweet text\n",
       "0            1  @Callisto1947 Can U Help?||More conservatives ...\n",
       "1            2  Just walked in to #Starbucks and asked for a \"...\n",
       "2            3                   GONNA WIN http://t.co/Mc9ebqjAqj\n",
       "3            4  @mickymantell He is exactly that sort of perso...\n",
       "4            5  So much at work mate 10/10 #boring 100% #dead ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"D:\\\\cseproject -- with Anita Mam\\\\semeval_dataset\\\\SemEval2018-Task3-master\\\\datasets\\\\test_TaskA\\\\SemEval2018-T3_input_test_taskA.txt\", sep='\\t')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = test_data[\"tweet text\"]\n",
    "train_tweets = train_data[\"Tweet text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing urls with word \"url\"\n",
    "processed1 = train_tweets.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'url')\n",
    "processed2 = test_tweets.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numbers with ''number''\n",
    "processed1 = processed1.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "processed2 = processed2.str.replace(r'\\d+(\\.\\d+)?', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Sweet United Nations video. Just in time for C...\n",
       "1    @mrdahlnumber We are rumored to have talked to...\n",
       "2    Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3             number episodes left I'm dying over here\n",
       "4    I can't breathe! was chosen as the most notabl...\n",
       "Name: Tweet text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @Callistonumber Can U Help?||More conservative...\n",
       "1    Just walked in to #Starbucks and asked for a \"...\n",
       "2                GONNA WIN http://t.co/McnumberebqjAqj\n",
       "3    @mickymantell He is exactly that sort of perso...\n",
       "4    So much at work mate number/number #boring num...\n",
       "Name: tweet text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed1 = processed1.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "processed2 = processed2.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed1 = processed1.str.replace(r'\\s+', ' ')\n",
    "processed2 = processed2.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed1 = processed1.str.replace(r'^\\s+|\\s+?$', '')\n",
    "processed2 = processed2.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change words to lower case\n",
    "processed1 = processed1.str.lower()\n",
    "processed2 = processed2.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    sweet united nations video just in time for ch...\n",
       "1    mrdahlnumber we are rumored to have talked to ...\n",
       "2    hey there nice to see you minnesota nd winter ...\n",
       "3             number episodes left i m dying over here\n",
       "4    i can t breathe was chosen as the most notable...\n",
       "Name: Tweet text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    callistonumber can u help more conservatives n...\n",
       "1    just walked in to starbucks and asked for a ta...\n",
       "2                  gonna win http t co mcnumberebqjaqj\n",
       "3    mickymantell he is exactly that sort of person...\n",
       "4    so much at work mate number number boring numb...\n",
       "Name: tweet text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed1 = processed1.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "\n",
    "processed2 = processed2.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove word stems using a Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed1 = processed1.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))\n",
    "\n",
    "processed2 = processed2.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    sweet unit nation video time christma imagin n...\n",
       "1    mrdahlnumb rumor talk erv agent angel ask ed e...\n",
       "2             hey nice see minnesota nd winter weather\n",
       "3                               number episod left die\n",
       "4    breath chosen notabl quot year annual list rel...\n",
       "Name: Tweet text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    callistonumb u help conserv need tsu get paid ...\n",
       "1                walk starbuck ask tall blond hahahaha\n",
       "2                    gonna win http co mcnumberebqjaqj\n",
       "3               mickymantel exactli sort person weirdo\n",
       "4    much work mate number number bore number dead ...\n",
       "Name: tweet text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# create bag-of-words\n",
    "all_words_train = []\n",
    "\n",
    "for message in processed1:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words_train.append(w)\n",
    "        \n",
    "all_words_train = nltk.FreqDist(all_words_train)\n",
    "\n",
    "all_words_test = []\n",
    "\n",
    "for message in processed2:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words_test.append(w)\n",
    "        \n",
    "all_words_test = nltk.FreqDist(all_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 10633\n",
      "Most common words: [('co', 943), ('http', 938), ('number', 679), ('love', 284), ('get', 229), ('day', 204), ('like', 196), ('go', 180), ('one', 142), ('work', 132), ('see', 129), ('time', 128), ('peopl', 121), ('great', 119), ('christma', 115)]\n",
      "Number of words: 3518\n",
      "Most common words: [('http', 218), ('co', 218), ('number', 120), ('get', 49), ('love', 47), ('like', 41), ('one', 40), ('day', 37), ('work', 33), ('peopl', 33), ('make', 31), ('good', 30), ('today', 29), ('go', 28), ('think', 28)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words_train)))\n",
    "print('Most common words: {}'.format(all_words_train.most_common(15)))\n",
    "\n",
    "print('Number of words: {}'.format(len(all_words_test)))\n",
    "print('Most common words: {}'.format(all_words_test.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features_train = list(all_words_train.keys())[:10500]\n",
    "\n",
    "word_features_test = list(all_words_test.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The find_features function will determine which of the 1500 word features are contained in the review\n",
    "def find_features_train(message):\n",
    "    words = word_tokenize(message)\n",
    "    features_train = {}\n",
    "    for word in word_features_train:\n",
    "        features_train[word] = (word in words)\n",
    "\n",
    "    return features_train\n",
    "\n",
    "def find_features_test(message):\n",
    "    words = word_tokenize(message)\n",
    "    features_test = {}\n",
    "    for word in word_features_test:\n",
    "        features_test[word] = (word in words)\n",
    "\n",
    "    return features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do it for all the messages\n",
    "messages_train = list(zip(processed1,classes))\n",
    "messages_test = list(processed2)\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages_train)\n",
    "np.random.shuffle(messages_test)\n",
    "\n",
    "# call find_features function for each tweet message\n",
    "featuresets_train = [(find_features_train(text), label) for (text, label) in messages_train]\n",
    "featuresets_test = [(find_features_test(text)) for (text) in messages_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets_train, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2862\n",
      "955\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_features, labels = zip(*testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 63.455497382198956\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 55.811518324607334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.56       487\n",
      "           1       0.55      0.55      0.55       468\n",
      "\n",
      "    accuracy                           0.56       955\n",
      "   macro avg       0.56      0.56      0.56       955\n",
      "weighted avg       0.56      0.56      0.56       955\n",
      "\n",
      "Decision Tree Accuracy: 59.58115183246073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62       487\n",
      "           1       0.60      0.54      0.57       468\n",
      "\n",
      "    accuracy                           0.60       955\n",
      "   macro avg       0.60      0.59      0.59       955\n",
      "weighted avg       0.60      0.60      0.59       955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwuj\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 63.769633507853406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       487\n",
      "           1       0.63      0.64      0.64       468\n",
      "\n",
      "    accuracy                           0.64       955\n",
      "   macro avg       0.64      0.64      0.64       955\n",
      "weighted avg       0.64      0.64      0.64       955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwuj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 64.92146596858639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       487\n",
      "           1       0.64      0.66      0.65       468\n",
      "\n",
      "    accuracy                           0.65       955\n",
      "   macro avg       0.65      0.65      0.65       955\n",
      "weighted avg       0.65      0.65      0.65       955\n",
      "\n",
      "SGD Classifier Accuracy: 62.5130890052356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       487\n",
      "           1       0.61      0.65      0.63       468\n",
      "\n",
      "    accuracy                           0.63       955\n",
      "   macro avg       0.63      0.63      0.63       955\n",
      "weighted avg       0.63      0.63      0.62       955\n",
      "\n",
      "Naive Bayes Accuracy: 65.44502617801047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63       487\n",
      "           1       0.63      0.72      0.67       468\n",
      "\n",
      "    accuracy                           0.65       955\n",
      "   macro avg       0.66      0.66      0.65       955\n",
      "weighted avg       0.66      0.65      0.65       955\n",
      "\n",
      "SVM Linear Accuracy: 63.455497382198956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63       487\n",
      "           1       0.62      0.65      0.63       468\n",
      "\n",
      "    accuracy                           0.63       955\n",
      "   macro avg       0.63      0.63      0.63       955\n",
      "weighted avg       0.64      0.63      0.63       955\n",
      "\n",
      "XGBoost Accuracy: 60.10471204188481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.46      0.54       487\n",
      "           1       0.57      0.74      0.65       468\n",
      "\n",
      "    accuracy                           0.60       955\n",
      "   macro avg       0.61      0.60      0.59       955\n",
      "weighted avg       0.61      0.60      0.59       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))\n",
    "    prediction = nltk_model.classify_many(txt_features)\n",
    "    print(classification_report(labels, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 60.10471204188481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class label prediction for testing set\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       487\n",
      "           1       0.64      0.62      0.63       468\n",
      "\n",
      "    accuracy                           0.65       955\n",
      "   macro avg       0.64      0.64      0.64       955\n",
      "weighted avg       0.64      0.65      0.64       955\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not irony</th>\n",
       "      <th>irony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">actual</td>\n",
       "      <td>not irony</td>\n",
       "      <td>324</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>irony</td>\n",
       "      <td>176</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted      \n",
       "                 not irony irony\n",
       "actual not irony       324   163\n",
       "       irony           176   292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['not irony', 'irony']],\n",
    "    columns = [['predicted', 'predicted'], ['not irony', 'irony']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1081 entries, 0 to 1080\n",
      "Data columns (total 2 columns):\n",
      "Tweets    1081 non-null object\n",
      "Task A    1081 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 17.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Task A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As the Bharatiya Janata Party (BJP) looks set ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>During the 1992 United States presidential el...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I don't tell lies like Modi ji. I believe in G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The BJP has a vision of India: one nation, on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Supreme Court on May 22 granted protection...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Task A\n",
       "0  As the Bharatiya Janata Party (BJP) looks set ...       0\n",
       "1   During the 1992 United States presidential el...       0\n",
       "2  I don't tell lies like Modi ji. I believe in G...       1\n",
       "3   The BJP has a vision of India: one nation, on...       0\n",
       "4  The Supreme Court on May 22 granted protection...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"election.csv\", encoding='utf-8')\n",
    "df2 = pd.read_csv(\"election1.csv\",encoding='utf-8')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     As the Bharatiya Janata Party (BJP) looks set ...\n",
       "1      During the 1992 United States presidential el...\n",
       "2     I don't tell lies like Modi ji. I believe in G...\n",
       "3      The BJP has a vision of India: one nation, on...\n",
       "4     The Supreme Court on May 22 granted protection...\n",
       "5       Many see the election as a referendum on Mr ...\n",
       "6     PATNA: RJD chief Lalu Prasadâ€™s elder son Tej P...\n",
       "7      NEW DELHI (AP) The Latest on India's general ...\n",
       "8      NEW DELHI (AP) Indians voted Sunday in the ne...\n",
       "9      Arrah in western Bihar, a constituency weighe...\n",
       "10     Ramalinga Reddy is the MLA of BTM Layout cons...\n",
       "11     New York: Time magazine, which published a co...\n",
       "12    Former IAS officer Arjun Ram Meghwal won the 2...\n",
       "13     Languages spoken in India belong to several l...\n",
       "14     BSP President Mayawati during an election cam...\n",
       "15     In the tweet, Kejriwal tagged Modi\\u2019s twe...\n",
       "16     BJP president Amit Shah will make his Lok Sab...\n",
       "17    BJP candidate Tejaswi Surya was able to receiv...\n",
       "18    This week has brought news once considered unt...\n",
       "19     The distancing of the BSP from the SP after t...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df[\"Tweets\"]\n",
    "tweets[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    749\n",
       "1    332\n",
       "Name: Task A, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['Task A']\n",
    "classes2 = df2['Task A']\n",
    "classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    759\n",
       "1    322\n",
       "Name: Task A, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780804029474862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inter-rater agreement Kappas (value changed at an interval of 16 in csv)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(classes, classes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing urls with word \"url\"\n",
    "processed = tweets.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numbers with ''number''\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    As the Bharatiya Janata Party (BJP) looks set ...\n",
       "1     During the number United States presidential ...\n",
       "2    I don't tell lies like Modi ji. I believe in G...\n",
       "3     The BJP has a vision of India: one nation, on...\n",
       "4    The Supreme Court on May number granted protec...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change words to lower case\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    as the bharatiya janata party bjp looks set fo...\n",
       "1    during the number united states presidential e...\n",
       "2    i don t tell lies like modi ji i believe in ga...\n",
       "3    the bjp has a vision of india one nation one h...\n",
       "4    the supreme court on may number granted protec...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove word stems using a Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bharatiya janata parti bjp look set massiv unp...\n",
       "1    number unit state presidenti elect campaign sl...\n",
       "2    tell lie like modi ji believ gandhi ji alway t...\n",
       "3    bjp vision india one nation one histori one cu...\n",
       "4    suprem court may number grant protect arrest t...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# create bag-of-words\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 4830\n",
      "Most common words: [('number', 1464), ('unumb', 691), ('char', 552), ('r', 497), ('modi', 491), ('elect', 482), ('minist', 405), ('parti', 404), ('bjp', 358), ('prime', 282), ('narendra', 267), ('congress', 240), ('india', 233), ('lok', 227), ('sabha', 220)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 4830 most common words as features\n",
    "word_features = list(all_words.keys())[:4830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The find_features function will determine which of the 1500 word features are contained in the review\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "# # Lets see an example!\n",
    "# features = find_features(processed[0])\n",
    "# for key, value in features.items():\n",
    "#     if value == True:\n",
    "#         print( key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do it for all the messages\n",
    "messages = list(zip(processed,classes))\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n",
      "271\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_features, labels = zip(*testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       194\n",
      "           1       0.67      0.79      0.73        77\n",
      "\n",
      "    accuracy                           0.83       271\n",
      "   macro avg       0.79      0.82      0.80       271\n",
      "weighted avg       0.84      0.83      0.83       271\n",
      "\n",
      "SVC Accuracy: 83.02583025830258\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "prediction = model.classify_many(txt_features)\n",
    "print(classification_report(labels, prediction))\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 60.51660516605166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.51      0.65       194\n",
      "           1       0.41      0.86      0.55        77\n",
      "\n",
      "    accuracy                           0.61       271\n",
      "   macro avg       0.65      0.68      0.60       271\n",
      "weighted avg       0.76      0.61      0.62       271\n",
      "\n",
      "Decision Tree Accuracy: 78.22878228782287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       194\n",
      "           1       0.60      0.73      0.65        77\n",
      "\n",
      "    accuracy                           0.78       271\n",
      "   macro avg       0.74      0.77      0.75       271\n",
      "weighted avg       0.80      0.78      0.79       271\n",
      "\n",
      "Random Forest Accuracy: 84.50184501845018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       194\n",
      "           1       0.75      0.68      0.71        77\n",
      "\n",
      "    accuracy                           0.85       271\n",
      "   macro avg       0.81      0.79      0.80       271\n",
      "weighted avg       0.84      0.85      0.84       271\n",
      "\n",
      "Logistic Regression Accuracy: 85.23985239852398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       194\n",
      "           1       0.71      0.81      0.76        77\n",
      "\n",
      "    accuracy                           0.85       271\n",
      "   macro avg       0.82      0.84      0.83       271\n",
      "weighted avg       0.86      0.85      0.85       271\n",
      "\n",
      "SGD Classifier Accuracy: 83.02583025830258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       194\n",
      "           1       0.67      0.78      0.72        77\n",
      "\n",
      "    accuracy                           0.83       271\n",
      "   macro avg       0.79      0.81      0.80       271\n",
      "weighted avg       0.84      0.83      0.83       271\n",
      "\n",
      "Naive Bayes Accuracy: 84.87084870848709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       194\n",
      "           1       0.71      0.78      0.75        77\n",
      "\n",
      "    accuracy                           0.85       271\n",
      "   macro avg       0.81      0.83      0.82       271\n",
      "weighted avg       0.85      0.85      0.85       271\n",
      "\n",
      "SVM Linear Accuracy: 83.02583025830258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       194\n",
      "           1       0.67      0.79      0.73        77\n",
      "\n",
      "    accuracy                           0.83       271\n",
      "   macro avg       0.79      0.82      0.80       271\n",
      "weighted avg       0.84      0.83      0.83       271\n",
      "\n",
      "XGBoost Accuracy: 82.65682656826569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       194\n",
      "           1       0.69      0.71      0.70        77\n",
      "\n",
      "    accuracy                           0.83       271\n",
      "   macro avg       0.79      0.79      0.79       271\n",
      "weighted avg       0.83      0.83      0.83       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    prediction = nltk_model.classify_many(txt_features)\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))\n",
    "    print(classification_report(labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting classifier accuracy :  85.97785977859779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\",\"XGBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    XGBClassifier()\n",
    "]\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, testing)*100\n",
    "print(\"voting classifier accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class label prediction for testing set\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       194\n",
      "           1       0.73      0.79      0.76        77\n",
      "\n",
      "    accuracy                           0.86       271\n",
      "   macro avg       0.82      0.84      0.83       271\n",
      "weighted avg       0.86      0.86      0.86       271\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>not irony</th>\n",
       "      <th>irony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">actual</td>\n",
       "      <td>not irony</td>\n",
       "      <td>172</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>irony</td>\n",
       "      <td>16</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted      \n",
       "                 not irony irony\n",
       "actual not irony       172    22\n",
       "       irony            16    61"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['not irony', 'irony']],\n",
    "    columns = [['predicted', 'predicted'], ['not irony', 'irony']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaaf27a7a0acc3437ba8317d9194673e70"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
